{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bro-ee/Jira-tickets-with-ChatGPT/blob/master/Google_Indexing_API_CSV_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://studiomakoto.it\">\n",
        "  <img src=\"https://studiomakoto.it/wp-content/uploads/2022/01/Logo-Studio-Makoto-Agenzia-di-Marketing-e-Comunicazione.jpg\" alt=\"Logo Studio Makoto\" width=\"120\" height=\"120\">\n",
        "</a>\n",
        "\n",
        "**Author**: <a href=\"https://studiomakoto.it/makoto_member/massimiliano-geraci/\">Max Geraci</a> |\n",
        "<a href=\"https://twitter.com/maxgeraci1\">\n",
        "  <img src=\"https://cdn-icons-png.flaticon.com/512/733/733579.png\" alt=\"Twitter Icon\" width=\"20\" height=\"20\">\n",
        "</a>"
      ],
      "metadata": {
        "id": "5gw8d4Wq_iEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fast Google Indexing via Indexing API\n",
        "\n",
        "Dear SEO enthusiasts, we're excited to introduce a quick and efficient method to submit your URLs directly to Google's Indexing API for immediate indexing. This approach allows you to send crawl requests straight to Google, making it an ideal solution for platforms like WordPress and Blogger.\n",
        "\n",
        "Google suggests that the Indexing API is mainly designed for pages embedding either 'JobPosting' or 'BroadcastEvent' within a 'VideoObject'. This makes it particularly useful for websites hosting ephemeral pages such as job postings or live-streamed videos frequently. By pushing individual updates, the Indexing API ensures your content remains up-to-date in search results.\n",
        "\n",
        "Interestingly, our tests reveal that this method also works flawlessly with other types of websites, extending its benefits beyond the initially intended usage.\n",
        "\n",
        "## What Can You Do with This Colab Notebook?\n",
        "\n",
        "This Colab notebook enables you to update or delete URLs from the Google Index and also to check the status of URLs.\n",
        "\n",
        "To achieve this, follow these steps:\n",
        "\n",
        "1. Import necessary libraries and upload your JSON key file (Cell 0).\n",
        "\n",
        "If you want to update or delete URLs:\n",
        "\n",
        "2. Upload your CSV or Excel file containing the URLs (Cell 1).\n",
        "3. Choose the request type: 'URL_UPDATED' to update the URL or 'URL_DELETED' to remove the URL from the index.\n",
        "\n",
        "If you want to check the URLs' indexing status:\n",
        "\n",
        "4. Upload your CSV or Excel file containing the URLs (Cell 2).\n",
        "5. The notebook will automatically check the status of each URL and save the results to a CSV file named 'indexed_urls.csv'.\n",
        "\n",
        "Please note that you can either perform URL updates/deletions or check the status of URLs based on your requirements.\n",
        "\n",
        "However, to get the Colab notebook to work, you'll need to generate the Indexing API from the Google Cloud Console. Additionally, you'll need to create a service account and add it as an owner in the Search Console account of the website you want to index through the API.\n",
        "\n",
        "For a detailed step-by-step guide, please refer to the following resources:\n",
        "\n",
        "1. [Google's official guide on using the Indexing API](https://developers.google.com/search/apis/indexing-api/v3/using-api)\n",
        "2. [RankMath's blog post on Google Indexing API](https://rankmath.com/blog/google-indexing-api/)\n",
        "\n",
        "Let's get started!"
      ],
      "metadata": {
        "id": "YN7geS23pGxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload your Indexing API credentials"
      ],
      "metadata": {
        "id": "mbkVaHqyH3JI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Run the cell.\n",
        "2. When prompted, select and upload your JSON credentials file.\n",
        "\n",
        "This JSON file should contain the private key for your service account, which you created as part of setting up access to the Indexing API.\n",
        "\n",
        "For more detailed instructions on creating and managing your service account credentials, please refer to the [Google Search Central developers guide](https://developers.google.com/search/apis/indexing-api/v3/prereqs#oauth)."
      ],
      "metadata": {
        "id": "XOAvPZr5BQJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Import Necessary Libraries and Upload JSON Key**\n",
        "from google.colab import files\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import httplib2\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Upload JSON Key\n",
        "try:\n",
        "  uploaded_key = files.upload()\n",
        "  for key, value in uploaded_key.items():\n",
        "    json_key_name = key\n",
        "  print('*'*50)\n",
        "  print(\"JSON Key uploaded successfully!\")\n",
        "  print('*'*50)\n",
        "except:\n",
        "  print('*'*50)\n",
        "  print(\"Error: Please try uploading the JSON Key again!\")\n",
        "  print('*'*50)\n",
        "\n",
        "# Define scopes and endpoints\n",
        "SCOPES = [\"https://www.googleapis.com/auth/indexing\"]\n",
        "ENDPOINT = \"https://indexing.googleapis.com/v3/urlNotifications:publish\"\n",
        "JSON_KEY_FILE = json_key_name\n",
        "\n",
        "# Authorize the JSON Key\n",
        "credentials = ServiceAccountCredentials.from_json_keyfile_name(JSON_KEY_FILE, scopes=SCOPES)\n",
        "http = credentials.authorize(httplib2.Http())\n",
        "print('*'*50)\n",
        "print(\"Credentials authorized successfully!\")\n",
        "print('*'*50)"
      ],
      "metadata": {
        "id": "M5jra9e6tEHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Upload CSV/Excel File and Send Indexing Requests**\n",
        "# Upload CSV or Excel file\n",
        "uploaded_file = files.upload()\n",
        "file_name = list(uploaded_file.keys())[0]\n",
        "requestType = \"URL_UPDATE\" #@param [\"URL_UPDATE\", \"URL_DELETE\"]\n",
        "\n",
        "# Read the file\n",
        "if '.csv' in file_name:\n",
        "    data = pd.read_csv(io.BytesIO(uploaded_file[file_name]))\n",
        "elif '.xls' in file_name:\n",
        "    data = pd.read_excel(io.BytesIO(uploaded_file[file_name]))\n",
        "\n",
        "# Get list of URLs\n",
        "urls = data.iloc[:,0].tolist()\n",
        "\n",
        "# Send indexing requests for each URL and print results\n",
        "for siteURL in urls:\n",
        "    content = str({'url':siteURL,'type':requestType})\n",
        "    response, content = http.request(ENDPOINT, method=\"POST\", body=content)\n",
        "    output = response['status']\n",
        "\n",
        "    if output == '200':\n",
        "        print(f\"Successfully Updated {siteURL}\")\n",
        "        print('*'*50)\n",
        "    else:\n",
        "        print(f\"Error Updating {siteURL}. Error Code: {output}\")\n",
        "        print(\"Visit Here For More: https://developers.google.com/search/apis/indexing-api/v3/core-errors#api-errors\")\n",
        "        print('*'*50)"
      ],
      "metadata": {
        "id": "jMkignjy9Rpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Upload CSV/Excel File, Check URLs, and Save Results**\n",
        "# Upload CSV or Excel file\n",
        "uploaded_file = files.upload()\n",
        "file_name = list(uploaded_file.keys())[0]\n",
        "\n",
        "# Read the file\n",
        "if '.csv' in file_name:\n",
        "    data = pd.read_csv(io.BytesIO(uploaded_file[file_name]))\n",
        "elif '.xls' in file_name:\n",
        "    data = pd.read_excel(io.BytesIO(uploaded_file[file_name]))\n",
        "\n",
        "# Get list of URLs\n",
        "urls = data.iloc[:,0].tolist()\n",
        "\n",
        "# Prepare a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=['url', 'is_indexed'])\n",
        "\n",
        "# Check each URL and save results\n",
        "for siteURL in urls:\n",
        "    content = str({'url':siteURL,'type':'URL_UPDATED'})\n",
        "    response, content = http.request(ENDPOINT, method=\"POST\", body=content)\n",
        "    output = response['status']\n",
        "\n",
        "    if output == '200':\n",
        "        temp_df = pd.DataFrame([{'url': siteURL, 'is_indexed': 'TRUE'}])\n",
        "    else:\n",
        "        temp_df = pd.DataFrame([{'url': siteURL, 'is_indexed': 'FALSE'}])\n",
        "\n",
        "    results_df = pd.concat([results_df, temp_df], ignore_index=True)\n",
        "\n",
        "# Save results to a CSV file\n",
        "output_file_name = 'Indexing_status_' + file_name.split('.')[0] + '.csv'\n",
        "results_df.to_csv(output_file_name, index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "files.download(output_file_name)\n",
        "\n",
        "print(f\"Results saved to '{output_file_name}' and downloaded.\")"
      ],
      "metadata": {
        "id": "LOz9uBsavVNY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}